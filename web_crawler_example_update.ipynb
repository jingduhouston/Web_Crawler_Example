{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get webpage using *requests*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "req = requests.get('https://en.wikipedia.org/wiki/Data_science')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#req.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UTF-8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpage = req.text\n",
    "type(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test.txt'\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(webpage.encode())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(webpage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get specific contents using BeatifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(webpage, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prettify the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Get the first paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to remove \"attrs\" to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>\n",
       "\t\t\tPages for logged out editors <a aria-label=\"Learn more about editing\" data-mw=\"interface\" href=\"/wiki/Help:Introduction\"><span>learn more</span></a>\n",
       "</p>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paragraph = soup.find('p', attrs={\"class\":False})\n",
    "paragraph = soup.find_all('p', attrs={\"class\":False})\n",
    "paragraph = paragraph[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p><b>Data science</b> is an <a class=\"mw-redirect\" href=\"/wiki/Interdisciplinary\" title=\"Interdisciplinary\">interdisciplinary</a> academic field <sup class=\"reference\" id=\"cite_ref-1\"><a href=\"#cite_note-1\">[1]</a></sup> that uses <a href=\"/wiki/Statistics\" title=\"Statistics\">statistics</a>, <a class=\"mw-redirect\" href=\"/wiki/Scientific_computing\" title=\"Scientific computing\">scientific computing</a>, <a href=\"/wiki/Scientific_method\" title=\"Scientific method\">scientific methods</a>, processes, <a href=\"/wiki/Algorithm\" title=\"Algorithm\">algorithms</a> and systems to extract or extrapolate <a href=\"/wiki/Knowledge\" title=\"Knowledge\">knowledge</a> and insights from noisy, structured, and <a href=\"/wiki/Unstructured_data\" title=\"Unstructured data\">unstructured data</a>.<sup class=\"reference\" id=\"cite_ref-2\"><a href=\"#cite_note-2\">[2]</a></sup>\n",
       "</p>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Get all the links in this paragraph which point to other webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"mw-redirect\" href=\"/wiki/Interdisciplinary\" title=\"Interdisciplinary\">interdisciplinary</a>,\n",
       " <a href=\"#cite_note-1\">[1]</a>,\n",
       " <a href=\"/wiki/Statistics\" title=\"Statistics\">statistics</a>,\n",
       " <a class=\"mw-redirect\" href=\"/wiki/Scientific_computing\" title=\"Scientific computing\">scientific computing</a>,\n",
       " <a href=\"/wiki/Scientific_method\" title=\"Scientific method\">scientific methods</a>,\n",
       " <a href=\"/wiki/Algorithm\" title=\"Algorithm\">algorithms</a>,\n",
       " <a href=\"/wiki/Knowledge\" title=\"Knowledge\">knowledge</a>,\n",
       " <a href=\"/wiki/Unstructured_data\" title=\"Unstructured data\">unstructured data</a>,\n",
       " <a href=\"#cite_note-2\">[2]</a>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"title\":[], \"href\":[]}\n",
    "for link in paragraph.find_all('a', attrs={\"title\":True}):\n",
    "    data[\"title\"].append(link[\"title\"])\n",
    "    data[\"href\"].append(link[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interdisciplinary</td>\n",
       "      <td>/wiki/Interdisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>/wiki/Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientific computing</td>\n",
       "      <td>/wiki/Scientific_computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scientific method</td>\n",
       "      <td>/wiki/Scientific_method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>/wiki/Algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Knowledge</td>\n",
       "      <td>/wiki/Knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unstructured data</td>\n",
       "      <td>/wiki/Unstructured_data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                        href\n",
       "0     Interdisciplinary     /wiki/Interdisciplinary\n",
       "1            Statistics            /wiki/Statistics\n",
       "2  Scientific computing  /wiki/Scientific_computing\n",
       "3     Scientific method     /wiki/Scientific_method\n",
       "4             Algorithm             /wiki/Algorithm\n",
       "5             Knowledge             /wiki/Knowledge\n",
       "6     Unstructured data     /wiki/Unstructured_data"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the contents from all the webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpages = []\n",
    "head = \"https://en.wikipedia.org\"\n",
    "for href in data[\"href\"]:\n",
    "    link = head + href\n",
    "    req = requests.get(link)\n",
    "    webpage = req.text\n",
    "    webpages.append(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99121"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(webpage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Futher readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 robots.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check robots.txt of the website to find out what are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"https://en.wikipedia.org/robots.txt\")\n",
    "webpage = req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "#print(soup.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would be banned, if you scrape a website too fast. Let your crawler sleep for a while after each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(5):\n",
    "    time.sleep(3)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pausing for extactly three seconds after each round is too robotic. Let's add some randomness to make your crawler looks more like a human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "for i in range(5):\n",
    "    t = 1 + 2 * random()\n",
    "    time.sleep(t)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Separate the codes for scraping from the ones for data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scraping is more vulnerable. Nothing is more annoying than your crawler breaks because of a bug in the data extraction part.  \n",
    "2. You never know what data you would need for modeling. So keep all the webpages you obtain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Chrome Driver and Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Start Chrome Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(r\"C:\\Users\\jingd\\OneDrive\\Documents\\DownloadPrograms\\chromedriver\\chromedriver.exe\")\n",
    "service.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 Define driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Remote(service.service_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 Get Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver.get(\"http://www.indeed.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.4 Input position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = driver.find_element(\"id\", \"text-input-what\")\n",
    "elem.clear()\n",
    "elem.send_keys(\"data scientist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.5 Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.6 Get current link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the tools make your crawler act even more like a human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=data+scientist&l=Houston%2C+TX&from=searchOnHP&vjk=de98f6b1bc8d004a\n"
     ]
    }
   ],
   "source": [
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.7 Quit Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "# DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
    "#driver = webdriver.Chrome(r\"C:\\Users\\jingd\\OneDrive\\Documents\\DownloadPrograms\\chromedriver\\chromedriver.exe\")  # Optional argument, if not specified will search path.\n",
    "\n",
    "ser = Service(r\"C:\\Users\\jingd\\OneDrive\\Documents\\DownloadPrograms\\chromedriver\\chromedriver.exe\")\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=ser, options=op)\n",
    "\n",
    "driver.get('http://www.google.com/');\n",
    "\n",
    "time.sleep(5) # Let the user actually see something!\n",
    "\n",
    "search_box = driver.find_element(\"name\", \"q\")\n",
    "\n",
    "search_box.send_keys('Techlent')\n",
    "\n",
    "search_box.submit()\n",
    "\n",
    "time.sleep(5) # Let the user actually see something!\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
